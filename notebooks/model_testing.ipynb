{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have not installed `wiscs` locally, run this cell\n",
    "!pip install git+https://github.com/w-decker/wiscs.git --quiet # REQUIRED FOR THIS NOTEBOOK\n",
    "!pip install git+https://github.com/w-decker/rinterface.git --quiet # REQUIRED FOR THIS NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always run this cell\n",
    "import wiscs\n",
    "from wiscs.simulate import DataGenerator\n",
    "from wiscs.utils import make_tasks\n",
    "\n",
    "import rinterface.rinterface as R\n",
    "\n",
    "from src.utils import fmt_script\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating data\n",
    "Data are generated using the [`wiscs`](https://github.com/w-decker/wiscs) framework. For now, arbitrary variance parameters and design choices are set to help \"build\" the linear model. Once a final model has been chosen, additional power analyses can be run to determine the exact experimental design criteria.\n",
    "\n",
    ">Please see [generate_data.ipynb](/notebooks/generate_data.ipynb) for information on how to use the `wiscs` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params set successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/wiscs-stats/lib/python3.12/site-packages/wiscs/simulate.py:163: UserWarning: Simulating data for MAIN hypothesis.\n",
      "  warnings.warn(\"Simulating data for MAIN hypothesis.\")\n"
     ]
    }
   ],
   "source": [
    "task = make_tasks(low=100, high=200, n=5)\n",
    "params = {\n",
    "    'word.perceptual': 100,'image.perceptual': 95,'word.conceptual': 100,'image.conceptual': 100, # latents\n",
    "          'word.task': task,     'image.task': task,                                              # tasks\n",
    "            'sd.item': None,    'sd.question': None,   'sd.subject': 20,         \"sd.error\": 50, \n",
    "'sd.subject_question': 15, 'sd.item_question': None,  # noise\n",
    "          'n.subject': 300 ,      'n.question': 5,          'n.item': 10,                          # design\n",
    "}\n",
    "wiscs.set_params(params)\n",
    "# Generate data\n",
    "DG = DataGenerator(); DG.fit_transform(seed=2025)\n",
    "# convert to Pandas DataFrame\n",
    "df = DG.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate in R with [`rinterface`](https://github.com/w-decker/rinterface)\n",
    "\n",
    "I have built a small interface between Python and R. Check out the repo [here](https://github.com/w-decker/rinterface). Essentially, it takes in a multiline string containing an R-valid script and runs that as a subprocess using the `Rscript` command. There's a lot more to it than that (check out the repo for examples and additional functionality), but that's the jist. For the sake of brevity, I've condensed the script we will be regularly running inside a function [`src.fmt_script()`](/notebooks/src/utils.py) (see line 144). This will keep the notebook cleaner. A few things to note on `fmt_script()`:\n",
    "\n",
    "### What's inside `fmt_script()`?\n",
    "1. Imports necessary packages, including `lme4` and `lmerTest`. \n",
    "2. Factorizes categorical variables (this is hardcoded in because we already know what variables are which)\n",
    "3. Establishes treatment codes for categorical variables. You can print the script to see more details.\n",
    "4. Runs the models and prints the summary of each\n",
    "5. Runs `anova` on the two models\n",
    "\n",
    "### What do _you_ need to give `fmt_script()`?\n",
    "1. The R formulas for the shared and separate model as a string\n",
    "2. The pandas dataframe containing the data\n",
    "\n",
    "### What if you want to add some more code?\n",
    "You can optionally specify a list of strings containing new lines of code. Each element in your list will be a new line. These are then added right before the model is run: \n",
    "\n",
    "```python\n",
    "fmt_script(shared_f=..., separate_f=..., df=df, add=['cat(\"hello world\")'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite's\n",
      "  method [lmerModLmerTest]\n",
      "Formula: rt ~ modality + question + (1 + question | subject)\n",
      "   Data: df\n",
      "\n",
      "      AIC       BIC    logLik  deviance  df.resid \n",
      " 322073.8  322256.6 -161014.9  322029.8     29978 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-3.8379 -0.6611 -0.0035  0.6698  3.6442 \n",
      "\n",
      "Random effects:\n",
      " Groups   Name        Variance Std.Dev. Corr                   \n",
      " subject  (Intercept)  639.1   25.28                           \n",
      "          question1    464.7   21.56    -0.49                  \n",
      "          question2    425.5   20.63    -0.53  0.49            \n",
      "          question3    521.3   22.83    -0.52  0.47  0.55      \n",
      "          question4    446.9   21.14    -0.52  0.58  0.52  0.57\n",
      " Residual             2509.7   50.10                           \n",
      "Number of obs: 30000, groups:  subject, 300\n",
      "\n",
      "Fixed effects:\n",
      "               Estimate Std. Error        df t value Pr(>|t|)    \n",
      "(Intercept)   2.942e+02  1.622e+00 3.200e+02 181.329   <2e-16 ***\n",
      "modalityimage 4.879e+00  5.785e-01 2.850e+04   8.435   <2e-16 ***\n",
      "question1     5.071e+01  1.544e+00 3.000e+02  32.834   <2e-16 ***\n",
      "question2     7.510e+01  1.502e+00 3.000e+02  50.012   <2e-16 ***\n",
      "question3     2.537e+01  1.604e+00 3.000e+02  15.814   <2e-16 ***\n",
      "question4     9.987e+01  1.525e+00 3.000e+02  65.481   <2e-16 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) mdltym qustn1 qustn2 qustn3\n",
      "modalityimg -0.178                            \n",
      "question1   -0.525  0.000                     \n",
      "question2   -0.547  0.000  0.494              \n",
      "question3   -0.548  0.000  0.481  0.534       \n",
      "question4   -0.546  0.000  0.549  0.512  0.544\n",
      "Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite's\n",
      "  method [lmerModLmerTest]\n",
      "Formula: rt ~ modality * question + (1 + question | subject)\n",
      "   Data: df\n",
      "\n",
      "      AIC       BIC    logLik  deviance  df.resid \n",
      " 322080.7  322296.7 -161014.3  322028.7     29974 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-3.8336 -0.6606 -0.0034  0.6702  3.6492 \n",
      "\n",
      "Random effects:\n",
      " Groups   Name        Variance Std.Dev. Corr                   \n",
      " subject  (Intercept)  639.0   25.28                           \n",
      "          question1    464.7   21.56    -0.49                  \n",
      "          question2    425.4   20.63    -0.53  0.49            \n",
      "          question3    521.2   22.83    -0.52  0.47  0.55      \n",
      "          question4    446.8   21.14    -0.52  0.58  0.52  0.57\n",
      " Residual             2509.6   50.10                           \n",
      "Number of obs: 30000, groups:  subject, 300\n",
      "\n",
      "Fixed effects:\n",
      "                          Estimate Std. Error         df t value Pr(>|t|)    \n",
      "(Intercept)              2.944e+02  1.722e+00  4.065e+02 170.946  < 2e-16 ***\n",
      "modalityimage            4.406e+00  1.293e+00  2.850e+04   3.406  0.00066 ***\n",
      "question1                5.030e+01  1.795e+00  5.466e+02  28.020  < 2e-16 ***\n",
      "question2                7.511e+01  1.758e+00  5.632e+02  42.721  < 2e-16 ***\n",
      "question3                2.461e+01  1.847e+00  5.262e+02  13.325  < 2e-16 ***\n",
      "question4                9.985e+01  1.778e+00  5.540e+02  56.150  < 2e-16 ***\n",
      "modalityimage:question1  8.316e-01  1.829e+00  2.850e+04   0.455  0.64940    \n",
      "modalityimage:question2 -2.262e-02  1.829e+00  2.850e+04  -0.012  0.99014    \n",
      "modalityimage:question3  1.526e+00  1.829e+00  2.850e+04   0.834  0.40408    \n",
      "modalityimage:question4  3.214e-02  1.829e+00  2.850e+04   0.018  0.98598    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) mdltym qustn1 qustn2 qustn3 qustn4 mdlt:1 mdlt:2 mdlt:3\n",
      "modalityimg -0.376                                                        \n",
      "question1   -0.561  0.360                                                 \n",
      "question2   -0.578  0.368  0.496                                          \n",
      "question3   -0.580  0.350  0.486  0.525                                   \n",
      "question4   -0.577  0.364  0.536  0.509  0.532                            \n",
      "mdltymg:qs1  0.266 -0.707 -0.510 -0.260 -0.248 -0.257                     \n",
      "mdltymg:qs2  0.266 -0.707 -0.255 -0.520 -0.248 -0.257  0.500              \n",
      "mdltymg:qs3  0.266 -0.707 -0.255 -0.260 -0.495 -0.257  0.500  0.500       \n",
      "mdltymg:qs4  0.266 -0.707 -0.255 -0.260 -0.248 -0.514  0.500  0.500  0.500\n",
      "\n",
      "Data: df\n",
      "Models:\n",
      "shared: rt ~ modality + question + (1 + question | subject)\n",
      "separate: rt ~ modality * question + (1 + question | subject)\n",
      "         npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)\n",
      "shared     22 322074 322257 -161015   322030                     \n",
      "separate   26 322081 322297 -161014   322029 1.1366  4     0.8884\n"
     ]
    }
   ],
   "source": [
    "script = fmt_script(shared_f=\"rt ~ modality + question + (1 + question | subject)\", \n",
    "                    separate_f=\"rt ~ modality * question + (1 + question | subject)\",\n",
    "                    df=df)\n",
    "R(script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does the rest of this notebook look like?\n",
    "\n",
    "Much of this notebook is evaluating different values specified in the data generation process and different formula's to specify a linear model. The point is to define a conceptually sound model that maximally aligns with the hypotheses laid out in the project. As such, the two previous codeblocks will be repeatedly run (in new cells) below. So much of what's written below is similar to you've already seen. All that's changed are values given to the data generator and the linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wiscs-stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
